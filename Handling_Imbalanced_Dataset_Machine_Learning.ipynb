{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handling Imbalanced Dataset Machine Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNN7C4MCXvUNwOEm269aeZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anand12yadav/Handling-Imbalanced-Dataset-Machine-Learning/blob/master/Handling_Imbalanced_Dataset_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcWxPAz58pV-",
        "colab_type": "text"
      },
      "source": [
        "# Handling imbalanced dataset in Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXspekDR8Wq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b44dfecd-8064-48e0-f3ab-c77a957152ac"
      },
      "source": [
        "!pip install imbalanced-learn "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSmL2FrG8-14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d9aebec4-fb28-4bb8-c055-ab0ca2fa0063"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pRzJpS7-twY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6eaf527b-299c-4d41-d738-0d473e2e4be8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqsDF9Zb-ynd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df8JXFHg--Ma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e6b15ad6-9769-468f-e966-852f0ad0c9d0"
      },
      "source": [
        "# dependent feature is Class here in the dataset\n",
        "# lets check how many 0's and 1's present \n",
        "# 0 represents not fraud , 1 reperesents fraud\n",
        "\n",
        "df[\"Class\"].value_counts()\n",
        "\n",
        "# Now we can see there is huge difference between the two so its imbalanced data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbLeRnl6AIIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dividing the dataset into independent and dependent feature (X=independent features , Y= dependent feature)\n",
        "\n",
        "X=df.drop(\"Class\",axis=1)\n",
        "Y=df[\"Class\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AwIq5tDMxOr",
        "colab_type": "text"
      },
      "source": [
        "*Cross Validation like KFOLD and Hyperparameter Tuning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5DhamXPBMSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets just apply logistic regression (you can choose any algo) algorithm to the dataset and see what happens \n",
        "# Just to check performance\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "from sklearn.model_selection import KFold # using this library for cross validation\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAm_Fa4vDHR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_class=LogisticRegression()\n",
        "# performing hyper parameter tuning \n",
        "# C ,penalty is the parameter prresent in LogisticRegression()\n",
        "grid={\"C\": 10.0**np.arange(-2,3),'penalty':['l1','l2']}\n",
        "cv=KFold(n_splits=5,shuffle=False,random_state=None)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSpi7O7SIGEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performing Train Test split \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,train_size=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPyFfJ-oKt0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "6732773c-25b5-487d-8d14-f3cef4bbd729"
      },
      "source": [
        "# n_jobs uses all the cores of the computer \n",
        "# f1_macro its like accuracy\n",
        "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
              "             error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA4PIVTdLLZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e230c85b-0af7-4ca9-9eee-7e724d9bd5db"
      },
      "source": [
        "y_predict=clf.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(accuracy_score(y_test,y_predict))  # better accuracy does not always means that the model is good, here we get 99% accuracy because the numbers of 1's were very very less than 0's\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85237    48]\n",
            " [   49   109]]\n",
            "0.9988647402361809\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85285\n",
            "           1       0.69      0.69      0.69       158\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.85      0.84      0.85     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJA_JK1HMhZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1ad07f0f-bf41-4ec7-ce31-105cf2f766b5"
      },
      "source": [
        "# Lets perform same with some other alogithm like RandomForest \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "# Here i have not performed cross validation,Hyperparameter tuning , we can perform if want similar to example above\n",
        "# If we apply cross validation and Hyperparameter tuning we will get more better results\n",
        "classifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsIDRQYhN5HY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8334a1b7-6469-4dda-bda2-7f75014782ec"
      },
      "source": [
        "y_predict=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(accuracy_score(y_test,y_predict))   \n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85276     9]\n",
            " [   39   119]]\n",
            "0.9994382219725431\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85285\n",
            "           1       0.93      0.75      0.83       158\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.96      0.88      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y1fAWfQQ7aW",
        "colab_type": "text"
      },
      "source": [
        "**Technique 1 :Under sampling** \n",
        "\n",
        " what do we do in undersampling ?\n",
        "\n",
        " Suppose we have 0 - 10000 values for 0 and 1-100 values for 1 as here the data is imbalanced .\n",
        " \n",
        " we will do undersampling ---undersampling will reduce the points of maximum labels , means here 0's points are maximum it will reduce 0's points from 1000 to 500 maybe or anything.\n",
        "\n",
        " This method has various disadvantages so it should not be used for large datasets , it ahould be used for small datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOqz1MazSfGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "aff06293-f4ea-4490-ea08-f65674f0fc12"
      },
      "source": [
        "y_train.value_counts()\n",
        "# we will try to reduce the 0's vaue by 80% as here we can see its values is way more than 1's"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    199030\n",
              "1       334\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKuyJrcwP7Mq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "36790660-ac79-46aa-da3a-07507b66cedd"
      },
      "source": [
        "# this library counts the number of 0's and 1's\n",
        "from collections import Counter\n",
        "# need this library to perform under sampling \n",
        "from imblearn.under_sampling import NearMiss\n",
        "ns = NearMiss(0.8)\n",
        "# we use fit_sample for this rather than fit()\n",
        "X_train_ns,y_train_ns=ns.fit_sample(X_train,y_train)\n",
        "print(\"The number of Class befor fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of Class after fit {}\".format(Counter(y_train_ns)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The number of Class befor fit Counter({0: 199030, 1: 334})\n",
            "The number of Class after fit Counter({0: 417, 1: 334})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9lDBfWTjLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4bc40a92-6073-4cd9-f63d-bf4f7676034b"
      },
      "source": [
        "# Lets perform same with some other alogithm like RandomForest \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "# Here i have not performed cross validation,Hyperparameter tuning , we can perform if want similar to example above\n",
        "# If we apply cross validation and Hyperparameter tuning we will get more better results\n",
        "classifier.fit(X_train_ns,y_train_ns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWRFGAuNVVYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ea17102c-c78c-49c6-df35-bd3a3841b021"
      },
      "source": [
        "y_predict=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(accuracy_score(y_test,y_predict))   \n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[61841 23444]\n",
            " [   12   146]]\n",
            "0.725477803916061\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.73      0.84     85285\n",
            "           1       0.01      0.92      0.01       158\n",
            "\n",
            "    accuracy                           0.73     85443\n",
            "   macro avg       0.50      0.82      0.43     85443\n",
            "weighted avg       1.00      0.73      0.84     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX0t6ypKVfKB",
        "colab_type": "text"
      },
      "source": [
        "# Technique 2 :Over Sampling.\n",
        "\n",
        " In over sampling those which has less values we increase their value. \n",
        "\n",
        " Here 1's values where less as compared to 0's , so we will increas the values of 1's.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaWqthb5Ver6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# library to perform over sampling \n",
        "from imblearn.over_sampling import RandomOverSampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGi_XLnbVx6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "baf44a63-b72c-4188-af6c-f9f7a3ba9644"
      },
      "source": [
        "# this library counts the number of 0's and 1's\n",
        "from collections import Counter\n",
        "os = RandomOverSampler(0.5)\n",
        "# we use fit_sample for this rather than fit()\n",
        "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
        "print(\"The number of Class befor fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of Class after fit {}\".format(Counter(y_train_ns)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of Class befor fit Counter({0: 199030, 1: 334})\n",
            "The number of Class after fit Counter({0: 199030, 1: 99515})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3gSoMHHWvUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ec918ca8-ed92-43ce-a779-a8b7c090b153"
      },
      "source": [
        "# Lets perform same with some other alogithm like RandomForest \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "# Here i have not performed cross validation,Hyperparameter tuning , we can perform if want similar to example above\n",
        "# If we apply cross validation and Hyperparameter tuning we will get more better results\n",
        "classifier.fit(X_train_ns,y_train_ns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_S1b_vkW8tX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "963b2fbd-7031-4656-a316-d69796fa207a"
      },
      "source": [
        "y_predict=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(accuracy_score(y_test,y_predict))   \n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85276     9]\n",
            " [   37   121]]\n",
            "0.9994616293903538\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85285\n",
            "           1       0.93      0.77      0.84       158\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.97      0.88      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gGMravjZRa7",
        "colab_type": "text"
      },
      "source": [
        "# Technique 3 : SMOTETomek\n",
        "\n",
        "This technique uses the combination of udersampling and oversampling.\n",
        "\n",
        "It creates new points for the lowest value among the two"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdg-QEnoZGVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Library used for this technique\n",
        "from imblearn.combine import  SMOTETomek\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCptoTARZwLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "603c6f4c-697c-4688-ed4f-40adbc62c9ea"
      },
      "source": [
        "# this library counts the number of 0's and 1's\n",
        "from collections import Counter\n",
        "os = SMOTETomek(0.75)\n",
        "# we use fit_sample for this rather than fit()\n",
        "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
        "print(\"The number of Class befor fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of Class after fit {}\".format(Counter(y_train_ns)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The number of Class befor fit Counter({0: 199030, 1: 334})\n",
            "The number of Class after fit Counter({0: 198463, 1: 148705})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2codJNwPa3-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4f26193b-12d1-4c8b-a393-72882324a1f1"
      },
      "source": [
        "# Lets perform same with some other alogithm like RandomForest \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "# Here i have not performed cross validation,Hyperparameter tuning , we can perform if want similar to example above\n",
        "# If we apply cross validation and Hyperparameter tuning we will get more better results\n",
        "classifier.fit(X_train_ns,y_train_ns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbErOrzwaJ68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4cd19d05-0182-4437-d665-751bf4206058"
      },
      "source": [
        "y_predict=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(accuracy_score(y_test,y_predict))   \n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85262    23]\n",
            " [   32   126]]\n",
            "0.9993562960102056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85285\n",
            "           1       0.85      0.80      0.82       158\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.92      0.90      0.91     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSGDhNbnb5yp",
        "colab_type": "text"
      },
      "source": [
        "# Technique 4 : Ensemble Techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHfIatbXb41L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# library to use this technique \n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrMvPaNucvoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "effd834a-6986-431e-cfc0-5101e6db5dc2"
      },
      "source": [
        "easy=EasyEnsembleClassifier()\n",
        "easy.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EasyEnsembleClassifier(base_estimator=None, n_estimators=10, n_jobs=1,\n",
              "                       random_state=None, replacement=False,\n",
              "                       sampling_strategy='auto', verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flm7jk6Vc_dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7e41bae3-f2a0-4027-f2be-56f0c231dd41"
      },
      "source": [
        "y_predict=easy.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(accuracy_score(y_test,y_predict))   \n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[82317  2968]\n",
            " [   16   142]]\n",
            "0.9650761326264293\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     85285\n",
            "           1       0.05      0.90      0.09       158\n",
            "\n",
            "    accuracy                           0.97     85443\n",
            "   macro avg       0.52      0.93      0.53     85443\n",
            "weighted avg       1.00      0.97      0.98     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}